# Awesome Calibration

> A curated list of awesome papers about calibration. If I missed any papers, feel free to open a PR to include them! And any feedback and contributions are welcome!

## Papers

- [On Calibration of Modern Neural Networks](https://arxiv.org/abs/1706.04599) *Chuan Guo et.al.* ICML 2017.
- [Revisiting the Calibration of Modern Neural Networks](https://arxiv.org/abs/2106.07998) *Matthias Minderer et.al.* NeurIPS 2021.

- [How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering](https://aclanthology.org/2021.tacl-1.57/) *Zhengbao Jiang et.al.* TACL 2021.

- [Language Models (Mostly) Know What They Know](https://arxiv.org/abs/2207.05221) *Saurav Kadavath et.al.* Arxiv 2022.

- [Do Large Language Models Know What They Don't Know?](https://arxiv.org/abs/2305.18153) *Zhangyue Yin et.al.* ACL 2023.

- [Investigating the Factual Knowledge Boundary of Large Language Models with Retrieval Augmentation](https://arxiv.org/abs/2307.11019) *Ruiyang Ren et.al.* Arxiv 2023.

- [Investigating Uncertainty Calibration of Aligned Language Models under the Multiple-Choice Setting](https://arxiv.org/abs/2310.11732) *Guande He et.al.* Arxiv 2023.

- [Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence Scores from Language Models Fine-Tuned with Human Feedback](https://arxiv.org/pdf/2305.14975.pdf) *Katherine Tian et.al.* EMNLP 2023.

- [On Uncertainty Calibration and Selective Generation in Probabilistic Neural Summarization: A Benchmark Study](https://aclanthology.org/2023.findings-emnlp.197/) *Polina Zablotskaia et.al.* EMNLP 2023.

- [Alignment for Honesty](https://arxiv.org/abs/2312.07000) *Yuqing Yang et.al.* Arxiv 2023.

- [When Do LLMs Need Retrieval Augmentation? Mitigating LLMsâ€™ Overconfidence Helps Retrieval Augmentation](https://arxiv.org/pdf/2402.11457.pdf) *Shiyu Ni et.al.* Arxiv 2024.

  